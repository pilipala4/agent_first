import re
import os
import json
import logging
from typing import Dict, Any, Optional, List, Union
from openai import OpenAI
from dotenv import load_dotenv
from functools import wraps
from logger import logger
from llm_call import LLMClient
from llm_call import DEFAULT_MODEL, DEFAULT_BASE_URL
from tools.tool_encapsulation import ToolManager, determine_tool_usage


from openai._exceptions import (
    AuthenticationError,
    RateLimitError,
    APIConnectionError,
    APIError
)

# å°è¯•å¯¼å…¥è¶…æ—¶å¼‚å¸¸ï¼Œå…¼å®¹ä¸åŒç‰ˆæœ¬
try:
    from openai._exceptions import APITimeoutError as Timeout
except ImportError:
    try:
        from openai import APITimeoutError as Timeout
    except ImportError:
        class Timeout(Exception):
            pass


# é‡æ„çš„ StructuredAgent ç±»
class StructuredAgent:
    def __init__(self, api_key: str = None):
        self.llm_client = LLMClient(api_key)
        self.tool_manager = ToolManager(api_key)  # æ·»åŠ å·¥å…·ç®¡ç†å™¨

    def process_with_tools(self, prompt: str, model: str = DEFAULT_MODEL) -> Dict[str, Any]:
        """
        å¤„ç†åŒ…å«å·¥å…·è°ƒç”¨çš„è¯·æ±‚
        """
        # é¦–å…ˆåˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·
        tool_decision = determine_tool_usage(prompt, self.tool_manager)

        if tool_decision["use_tool"]:
            # éœ€è¦ä½¿ç”¨å·¥å…·
            tool_name = tool_decision["tool_name"]
            arguments = tool_decision["arguments"]

            # è°ƒç”¨ç›¸åº”å·¥å…·
            tool_func = self.tool_manager.tools[tool_name]
            tool_result = tool_func(**arguments)

            # å°†å·¥å…·ç»“æœæ•´åˆåˆ°æç¤ºä¸­
            if tool_result["success"]:
                enhanced_prompt = f"""
    åŸå§‹é—®é¢˜ï¼š{prompt}

    å·¥å…·è°ƒç”¨ç»“æœï¼š
    {json.dumps(tool_result, ensure_ascii=False, indent=2)}

    è¯·åŸºäºä»¥ä¸Šä¿¡æ¯å›ç­”åŸå§‹é—®é¢˜ã€‚
    """
            else:
                enhanced_prompt = f"""
    åŸå§‹é—®é¢˜ï¼š{prompt}

    å·¥å…·è°ƒç”¨å¤±è´¥ï¼š{tool_result.get('error', 'æœªçŸ¥é”™è¯¯')}

    è¯·å°è¯•å…¶ä»–æ–¹å¼å›ç­”é—®é¢˜æˆ–å‘ŠçŸ¥ç”¨æˆ·å·¥å…·è°ƒç”¨å¤±è´¥ã€‚
    """

            # ä½¿ç”¨å¢å¼ºåçš„æç¤ºè°ƒç”¨LLM
            return self.chat_completion(enhanced_prompt, model=model)
        else:
            # ä¸éœ€è¦å·¥å…·ï¼Œç›´æ¥å¤„ç†åŸé—®é¢˜
            return self.chat_completion(prompt, model=model)

    def create_math_prompt(self, problem: str) -> str:
        """åˆ›å»ºæ•°å­¦è§£é¢˜çš„ç»“æ„åŒ–æç¤ºè¯"""
        return f"""
è¯·ä½¿ç”¨æ€ç»´é“¾ï¼ˆChain of Thoughtï¼‰æ–¹æ³•è§£å†³ä»¥ä¸‹æ•°å­¦é—®é¢˜ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ç»“æ„åŒ–ç»“æœï¼š

é—®é¢˜ï¼š{problem}

è¦æ±‚æ­¥éª¤ï¼š
1. é¦–å…ˆåˆ†æé—®é¢˜çš„å…³é”®ä¿¡æ¯
2. åˆ—å‡ºè§£é¢˜æ€è·¯å’Œæ­¥éª¤
3. é€æ­¥æ¨å¯¼è®¡ç®—è¿‡ç¨‹
4. å¾—å‡ºæœ€ç»ˆç­”æ¡ˆ
5. éªŒè¯ç­”æ¡ˆçš„åˆç†æ€§

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
{{
  "problem": "...",
  "analysis": "...",
  "steps": [
    {{
      "step_number": 1,
      "description": "...",
      "calculation": "..."
    }}
  ],
  "final_answer": "...",
  "verification": "..."
}}
"""

    def create_copywriting_prompt(self, requirements: str) -> str:
        """åˆ›å»ºæ–‡æ¡ˆç”Ÿæˆçš„ç»“æ„åŒ–æç¤ºè¯"""
        return f"""
è¯·ä½¿ç”¨æ€ç»´é“¾ï¼ˆChain of Thoughtï¼‰æ–¹æ³•ç”Ÿæˆæ»¡è¶³ä»¥ä¸‹è¦æ±‚çš„æ–‡æ¡ˆï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ç»“æ„åŒ–ç»“æœï¼š

éœ€æ±‚ï¼š{requirements}

è¦æ±‚æ­¥éª¤ï¼š
1. åˆ†ææ–‡æ¡ˆç›®æ ‡å—ä¼—å’Œç›®çš„
2. ç¡®å®šæ–‡æ¡ˆé£æ ¼å’Œè¯­è°ƒ
3. æ„æ€æ ¸å¿ƒä¿¡æ¯å’Œè¦ç‚¹
4. ç»„ç»‡æ–‡æ¡ˆç»“æ„
5. æ’°å†™æ–‡æ¡ˆå†…å®¹

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
{{
  "requirement": "...",
  "target_audience": "...",
  "style_tone": "...",
  "key_points": ["...", "..."],
  "structure_plan": "...",
  "generated_copy": "...",
  "call_to_action": "..."
}}
"""

    def chat_completion(self, prompt: str, model: str = DEFAULT_MODEL, retry_times: int = 3) -> Dict[str, Any]:
        """é€šç”¨èŠå¤©å®Œæˆæ–¹æ³•"""
        result = self.llm_client.call_llm(
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ“…é•¿ä½¿ç”¨æ€ç»´é“¾æ–¹æ³•è¿›è¡Œé€»è¾‘æ¨ç†å’Œå†…å®¹åˆ›ä½œã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ç»“æ„åŒ–è¾“å‡ºã€‚"
                },
                {"role": "user", "content": prompt}
            ],
            model=model,
            response_format={"type": "json_object"},
            retry_times=retry_times
        )

        if result["success"]:
            try:
                parsed_content = json.loads(result["data"])
                result["parsed_data"] = parsed_content
            except json.JSONDecodeError:
                logger.error("JSON è§£æå¤±è´¥")
                result["parsed_data"] = None

        return result


class ConversationAgent:
    def __init__(self, api_key: str = None):
        self.agent = StructuredAgent(api_key=api_key)
        # å­˜å‚¨å¯¹è¯å†å²
        self.conversation_history: List[Dict[str, str]] = []
        # ç”¨æˆ·è¾“å…¥éªŒè¯è§„åˆ™
        self.input_validator = InputValidator()

    def validate_input(self, user_input: str) -> tuple[bool, str]:
        """éªŒè¯ç”¨æˆ·è¾“å…¥çš„åˆæ³•æ€§"""
        return self.input_validator.validate(user_input)

    def add_to_history(self, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°å¯¹è¯å†å²"""
        self.conversation_history.append({
            "role": role,
            "content": content,
            "timestamp": self._get_timestamp()
        })

    def get_conversation_context(self) -> List[Dict[str, str]]:
        """è·å–å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡"""
        return self.conversation_history.copy()

    def handle_history_query(self, user_input: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå†å²æŸ¥è¯¢è¯·æ±‚"""
        history_keywords = [
            "å‰é¢é—®äº†ä»€ä¹ˆ", "ä¹‹å‰çš„é—®é¢˜", "å†å²è®°å½•",
            "å¯¹è¯å†å²", " earlier questions", "previous questions"
        ]
        return any(keyword in user_input.lower() for keyword in history_keywords)

    def get_previous_questions_summary(self) -> str:
        """è·å–ä¹‹å‰é—®é¢˜çš„æ‘˜è¦"""
        user_messages = [
            msg for msg in self.conversation_history
            if msg["role"] == "user" and msg["content"] != "æˆ‘è¿™è½®å¯¹è¯ä¸­å‰é¢é—®äº†ä»€ä¹ˆé—®é¢˜"
        ]

        if len(user_messages) <= 1:  # åªæœ‰å½“å‰è¿™ä¸ªé—®é¢˜
            return "è¿™æ˜¯æˆ‘ä»¬ç¬¬ä¸€è½®å¯¹è¯ï¼Œæ‚¨è¿˜æ²¡æœ‰é—®è¿‡å…¶ä»–é—®é¢˜ã€‚"

        previous_questions = [msg["content"] for msg in user_messages[:-1]]
        return f"æ‚¨ä¹‹å‰é—®è¿‡çš„é—®é¢˜åŒ…æ‹¬ï¼š{'ï¼›'.join(previous_questions)}"

    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history.clear()

    def chat(self, user_input: str) -> Dict[str, Any]:
        # éªŒè¯è¾“å…¥
        is_valid, validation_msg, cleaned_input = self.input_validator.validate_and_clean(user_input)
        #is_valid, validation_msg = self.validate_input(user_input)
        if not is_valid:
            return {
                "success": False,
                "error_type": "InputValidationError",
                "error_message": validation_msg,
                "data": None
            }
        # ç‰¹æ®Šå¤„ç†ï¼šå†å²æŸ¥è¯¢
        if self.handle_history_query(cleaned_input):
            summary = self.get_previous_questions_summary()
            self.add_to_history("assistant", summary)
            return {
                "success": True,
                "data": summary,
                "parsed_data": {"summary": summary}
            }

        # æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°å†å²è®°å½•
        self.add_to_history("user", cleaned_input)
        #self.add_to_history("user", user_input)

        try:
            '''
            # æ„å»ºå®Œæ•´çš„æ¶ˆæ¯å†å²
            messages = self._build_messages()

            # è°ƒç”¨ LLM
            response = self.agent.chat_completion(
                prompt=self._format_current_prompt(cleaned_input),
                retry_times=2
            )
            '''
            # ä½¿ç”¨å·¥å…·å¢å¼ºå¤„ç†
            response = self.agent.process_with_tools(cleaned_input)

            if response["success"]:
                # å®‰å…¨åœ°è·å–åŠ©æ‰‹å›å¤
                parsed_data = response.get("parsed_data")
                if isinstance(parsed_data, dict):
                    assistant_reply = parsed_data.get("generated_copy", response["data"])
                elif isinstance(parsed_data, (int, float)):  # å¦‚æœæ˜¯æ•°å­—ç±»å‹
                    assistant_reply = str(parsed_data)
                else:
                    assistant_reply = response.get("data", "")

                self.add_to_history("assistant", assistant_reply)
                return response
            else:
                # å‘ç”Ÿé”™è¯¯æ—¶ä»è®°å½•åˆ°å†å²
                error_msg = f"åŠ©æ‰‹æš‚æ—¶æ— æ³•å›åº”: {response['error_message']}"
                self.add_to_history("assistant", error_msg)
                return response  # ç¡®ä¿è¿”å›response

        except Exception as e:
            error_msg = f"å¯¹è¯å¤„ç†å‡ºé”™: {str(e)}"
            self.add_to_history("assistant", error_msg)
            logger.error(error_msg)
            return {
                "success": False,
                "error_type": "ConversationError",
                "error_message": error_msg,
                "data": None
            }

    def _build_messages(self) -> List[Dict[str, str]]:
        """æ„å»ºå®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨"""
        # ä½¿ç”¨æœ€è¿‘çš„å‡ è½®å¯¹è¯ä½œä¸ºä¸Šä¸‹æ–‡
        recent_history = self.conversation_history[-6:]  # æœ€è¿‘3è½®å¯¹è¯ï¼ˆç”¨æˆ·+åŠ©æ‰‹ï¼‰

        messages = [{
            "role": "system",
            "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿè¿›è¡Œå¤šè½®å¯¹è¯ã€‚è¯·å‚è€ƒä¹‹å‰çš„å¯¹è¯å†å²æ¥å›ç­”é—®é¢˜ã€‚"
        }]

        for msg in recent_history:
            messages.append({
                "role": msg["role"],
                "content": f"[{msg['timestamp']}] {msg['content']}"
            })

        return messages

    def _format_current_prompt(self, user_input: str) -> str:
        """æ ¼å¼åŒ–å½“å‰ç”¨æˆ·çš„è¾“å…¥"""
        if len(self.conversation_history) <= 2:  # åªæœ‰å½“å‰è¿™æ¬¡è¾“å…¥
            return user_input
        else:
            # æä¾›å¯¹è¯ä¸Šä¸‹æ–‡
            context = "\n".join([
                f"{msg['role']}: {msg['content']}"
                for msg in self.conversation_history[-4:]  # æœ€è¿‘2è½®
            ])
            return f"ä¹‹å‰çš„å¯¹è¯:\n{context}\n\nç°åœ¨çš„é—®é¢˜: {user_input}"

    def _get_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


class InputValidator:
    """ç”¨æˆ·è¾“å…¥éªŒè¯å™¨"""

    def __init__(self):
        # å®šä¹‰éæ³•å­—ç¬¦æ¨¡å¼
        self.invalid_patterns = [
            r'[<>{}[\]\\]',  # HTML/XMLæ ‡ç­¾å­—ç¬¦
            r'(\n\s*){3,}',  # è¿‡å¤šçš„ç©ºè¡Œ
        ]
        # å®šä¹‰æœ€å¤§è¾“å…¥é•¿åº¦
        self.max_length = 1000
        # å®šä¹‰æœ€å°æœ‰æ•ˆé•¿åº¦
        self.min_length = 1

    def validate_and_clean(self, user_input: str) -> tuple[bool, str, str]:
        """éªŒè¯å¹¶æ¸…ç†ç”¨æˆ·è¾“å…¥"""
        if user_input is None:
            return False, "è¾“å…¥ä¸èƒ½ä¸ºç©º", ""

        # æ¸…ç†ä»£ç†å­—ç¬¦
        try:
            cleaned_input = user_input.encode('utf-8', errors='ignore').decode('utf-8')
        except Exception:
            cleaned_input = user_input

        # åŸæœ‰çš„éªŒè¯é€»è¾‘
        stripped_input = cleaned_input.strip()

        if not stripped_input:
            return False, "è¯·è¾“å…¥æœ‰æ•ˆå†…å®¹", ""

        if len(stripped_input) < self.min_length:
            return False, "è¾“å…¥å†…å®¹å¤ªçŸ­ï¼Œè¯·è¾“å…¥æ›´å¤šå†…å®¹", ""

        if len(stripped_input) > self.max_length:
            return False, f"è¾“å…¥å†…å®¹å¤ªé•¿ï¼Œæœ€å¤šå…è®¸{self.max_length}ä¸ªå­—ç¬¦", ""

        for pattern in self.invalid_patterns:
            if re.search(pattern, stripped_input):
                return False, "è¾“å…¥åŒ…å«éæ³•å­—ç¬¦ï¼Œè¯·é‡æ–°è¾“å…¥", ""

        special_char_ratio = sum(1 for c in stripped_input if not c.isalnum() and not c.isspace()) / len(stripped_input)
        if special_char_ratio > 0.7:
            return False, "è¾“å…¥åŒ…å«è¿‡å¤šç‰¹æ®Šå­—ç¬¦ï¼Œè¯·ä½¿ç”¨æ­£å¸¸æ–‡å­—", ""

        return True, "è¾“å…¥æœ‰æ•ˆ", stripped_input


def interactive_chat():
    """äº¤äº’å¼èŠå¤©ç•Œé¢"""
    print("=== AI å¯¹è¯åŠ©æ‰‹ ===")
    print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºå¯¹è¯")
    print("è¾“å…¥ 'clear' æ¸…ç©ºå¯¹è¯å†å²")
    print("è¾“å…¥ 'history' æŸ¥çœ‹å¯¹è¯å†å²")
    print("-" * 30)

    # åˆå§‹åŒ–å¯¹è¯åŠ©æ‰‹
    agent = ConversationAgent()

    while True:
        try:
            user_input = input("\næ‚¨: ").strip()

            # å¤„ç†ç‰¹æ®Šå‘½ä»¤
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                print("å†è§ï¼")
                break
            elif user_input.lower() == 'clear':
                agent.clear_history()
                print("ğŸ¤– åŠ©æ‰‹: å¯¹è¯å†å²å·²æ¸…ç©º")
                continue
            elif user_input.lower() == 'history':
                history = agent.get_conversation_context()
                if history:
                    print("ğŸ¤– å¯¹è¯å†å²:")
                    for i, msg in enumerate(history, 1):
                        print(f"  {i}. [{msg['role']}] {msg['content']}")
                else:
                    print("ğŸ¤– åŠ©æ‰‹: å½“å‰æ²¡æœ‰å¯¹è¯å†å²")
                continue
            elif not user_input:
                print("ğŸ¤– åŠ©æ‰‹: è¯·è¾“å…¥æœ‰æ•ˆå†…å®¹")
                continue

            # å¤„ç†ç”¨æˆ·è¾“å…¥
            result = agent.chat(user_input)

            if result["success"]:
                response_data = result.get("parsed_data") or result.get("data")
                if isinstance(response_data, dict):
                    # å¦‚æœæ˜¯ç»“æ„åŒ–æ•°æ®ï¼Œæå–ä¸»è¦å†…å®¹
                    content = response_data.get("generated_copy") or response_data.get("final_answer") or str(
                        response_data)
                else:
                    content = response_data

                print(f"ğŸ¤– åŠ©æ‰‹: {content}")
            else:
                print(f"ğŸ¤– åŠ©æ‰‹: {result['error_message']}")

        except KeyboardInterrupt:
            print("\n\nå¯¹è¯è¢«ä¸­æ–­ï¼Œå†è§ï¼")
            break
        except Exception as e:
            print(f"ğŸ¤– åŠ©æ‰‹: å‘ç”Ÿé”™è¯¯ - {str(e)}")


if __name__ == '__main__':
    # è¿è¡Œäº¤äº’å¼èŠå¤©
    interactive_chat()
