import re
import os
import json
import logging
from typing import Dict, Any, Optional, List, Union
from openai import OpenAI
from dotenv import load_dotenv
from functools import wraps
from logger import logger
from llm_call import LLMClient
from llm_call import DEFAULT_MODEL, DEFAULT_BASE_URL
from tools.tool_encapsulation import ToolManager, determine_tool_usage

from openai._exceptions import (
    AuthenticationError,
    RateLimitError,
    APIConnectionError,
    APIError
)

# å°è¯•å¯¼å…¥è¶…æ—¶å¼‚å¸¸ï¼Œå…¼å®¹ä¸åŒç‰ˆæœ¬
try:
    from openai._exceptions import APITimeoutError as Timeout
except ImportError:
    try:
        from openai import APITimeoutError as Timeout
    except ImportError:
        class Timeout(Exception):
            pass


class StructuredAgent:
    def __init__(self, api_key: str = None):
        self.llm_client = LLMClient(api_key)
        self.tool_manager = ToolManager(api_key)

    def process_with_tools(self, prompt: str, context_history: List[Dict] = None, model: str = DEFAULT_MODEL) -> Dict[str, Any]:
        """
        å¤„ç†åŒ…å«å·¥å…·è°ƒç”¨çš„è¯·æ±‚ï¼Œæ”¯æŒå¯¹è¯ä¸Šä¸‹æ–‡
        """
        tool_decision = determine_tool_usage(prompt, self.tool_manager)

        if tool_decision["use_tool"]:
            tool_name = tool_decision["tool_name"]
            arguments = tool_decision["arguments"]

            tool_func = self.tool_manager.tools[tool_name]
            tool_result = tool_func(**arguments)

            # æ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            context_str = ""
            if context_history:
                context_str = f"æ ¹æ®ä»¥ä¸‹å¯¹è¯å†å²èƒŒæ™¯ï¼š\n{json.dumps(context_history, ensure_ascii=False, indent=2)}"

            if tool_result["success"]:
                enhanced_prompt = f"""
åŸå§‹é—®é¢˜ï¼š{prompt}

å·¥å…·è°ƒç”¨ç»“æœï¼š
{json.dumps(tool_result, ensure_ascii=False, indent=2)}

{context_str}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯å›ç­”åŸå§‹é—®é¢˜ã€‚
""".strip()
            else:
                enhanced_prompt = f"""
åŸå§‹é—®é¢˜ï¼š{prompt}

å·¥å…·è°ƒç”¨å¤±è´¥ï¼š{tool_result.get('error', 'æœªçŸ¥é”™è¯¯')}

{context_str}

è¯·å°è¯•å…¶ä»–æ–¹å¼å›ç­”é—®é¢˜æˆ–å‘ŠçŸ¥ç”¨æˆ·å·¥å…·è°ƒç”¨å¤±è´¥ã€‚
""".strip()

            return self.chat_completion(enhanced_prompt, model=model)
        else:
            # ä¸ä½¿ç”¨å·¥å…·ï¼šå°†ä¸Šä¸‹æ–‡èå…¥æç¤º
            if context_history:
                context_str = "\n".join([
                    f"{msg['role']}: {msg['content']}"
                    for msg in context_history[-6:]  # æœ€è¿‘2è½®å¯¹è¯
                ])
                full_prompt = f"ä¹‹å‰çš„å¯¹è¯:\n{context_str}\n\nå½“å‰é—®é¢˜: {prompt}"
            else:
                full_prompt = prompt

            return self.chat_completion(full_prompt, model=model)

    def create_math_prompt(self, problem: str) -> str:
        return f"""
è¯·ä½¿ç”¨æ€ç»´é“¾ï¼ˆChain of Thoughtï¼‰æ–¹æ³•è§£å†³ä»¥ä¸‹æ•°å­¦é—®é¢˜ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ç»“æ„åŒ–ç»“æœï¼š

é—®é¢˜ï¼š{problem}

è¦æ±‚æ­¥éª¤ï¼š
1. é¦–å…ˆåˆ†æé—®é¢˜çš„å…³é”®ä¿¡æ¯
2. åˆ—å‡ºè§£é¢˜æ€è·¯å’Œæ­¥éª¤
3. é€æ­¥æ¨å¯¼è®¡ç®—è¿‡ç¨‹
4. å¾—å‡ºæœ€ç»ˆç­”æ¡ˆ
5. éªŒè¯ç­”æ¡ˆçš„åˆç†æ€§

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
{{
  "problem": "...",
  "analysis": "...",
  "steps": [
    {{
      "step_number": 1,
      "description": "...",
      "calculation": "..."
    }}
  ],
  "final_answer": "...",
  "verification": "..."
}}
"""

    def create_copywriting_prompt(self, requirements: str) -> str:
        return f"""
è¯·ä½¿ç”¨æ€ç»´é“¾ï¼ˆChain of Thoughtï¼‰æ–¹æ³•ç”Ÿæˆæ»¡è¶³ä»¥ä¸‹è¦æ±‚çš„æ–‡æ¡ˆï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ç»“æ„åŒ–ç»“æœï¼š

éœ€æ±‚ï¼š{requirements}

è¦æ±‚æ­¥éª¤ï¼š
1. åˆ†ææ–‡æ¡ˆç›®æ ‡å—ä¼—å’Œç›®çš„
2. ç¡®å®šæ–‡æ¡ˆé£æ ¼å’Œè¯­è°ƒ
3. æ„æ€æ ¸å¿ƒä¿¡æ¯å’Œè¦ç‚¹
4. ç»„ç»‡æ–‡æ¡ˆç»“æ„
5. æ’°å†™æ–‡æ¡ˆå†…å®¹

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
{{
  "requirement": "...",
  "target_audience": "...",
  "style_tone": "...",
  "key_points": ["...", "..."],
  "structure_plan": "...",
  "generated_copy": "...",
  "call_to_action": "..."
}}
"""

    def chat_completion(self, prompt: str, model: str = DEFAULT_MODEL, retry_times: int = 3) -> Dict[str, Any]:
        result = self.llm_client.call_llm(
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ“…é•¿ä½¿ç”¨æ€ç»´é“¾æ–¹æ³•è¿›è¡Œé€»è¾‘æ¨ç†å’Œå†…å®¹åˆ›ä½œã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ç»“æ„åŒ–è¾“å‡ºã€‚"
                },
                {"role": "user", "content": prompt}
            ],
            model=model,
            response_format={"type": "json_object"},
            retry_times=retry_times
        )

        if result["success"]:
            try:
                parsed_content = json.loads(result["data"])
                result["parsed_data"] = parsed_content
            except json.JSONDecodeError:
                logger.error("JSON è§£æå¤±è´¥")
                result["parsed_data"] = None

        return result


class InputValidator:
    def __init__(self):
        self.invalid_patterns = [
            r'[<>{}[\]\\]',
            r'(\n\s*){3,}',
        ]
        self.max_length = 1000
        self.min_length = 1

    def validate_and_clean(self, user_input: str) -> tuple[bool, str, str]:
        if user_input is None:
            return False, "è¾“å…¥ä¸èƒ½ä¸ºç©º", ""

        try:
            cleaned_input = user_input.encode('utf-8', errors='ignore').decode('utf-8')
        except Exception:
            cleaned_input = user_input

        stripped_input = cleaned_input.strip()

        if not stripped_input:
            return False, "è¯·è¾“å…¥æœ‰æ•ˆå†…å®¹", ""

        if len(stripped_input) < self.min_length:
            return False, "è¾“å…¥å†…å®¹å¤ªçŸ­ï¼Œè¯·è¾“å…¥æ›´å¤šå†…å®¹", ""

        if len(stripped_input) > self.max_length:
            return False, f"è¾“å…¥å†…å®¹å¤ªé•¿ï¼Œæœ€å¤šå…è®¸{self.max_length}ä¸ªå­—ç¬¦", ""

        for pattern in self.invalid_patterns:
            if re.search(pattern, stripped_input):
                return False, "è¾“å…¥åŒ…å«éæ³•å­—ç¬¦ï¼Œè¯·é‡æ–°è¾“å…¥", ""

        special_char_ratio = sum(1 for c in stripped_input if not c.isalnum() and not c.isspace()) / len(stripped_input)
        if special_char_ratio > 0.7:
            return False, "è¾“å…¥åŒ…å«è¿‡å¤šç‰¹æ®Šå­—ç¬¦ï¼Œè¯·ä½¿ç”¨æ­£å¸¸æ–‡å­—", ""

        return True, "è¾“å…¥æœ‰æ•ˆ", stripped_input


class ConversationAgent:
    def __init__(self, api_key: str = None):
        self.agent = StructuredAgent(api_key=api_key)
        self.conversation_history: List[Dict[str, str]] = []
        self.input_validator = InputValidator()

    def add_to_history(self, role: str, content: str):
        from datetime import datetime
        self.conversation_history.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        })

    def get_conversation_context(self) -> List[Dict[str, str]]:
        return self.conversation_history.copy()

    def clear_history(self):
        self.conversation_history.clear()

    def chat(self, user_input: str) -> Dict[str, Any]:
        is_valid, validation_msg, cleaned_input = self.input_validator.validate_and_clean(user_input)
        if not is_valid:
            return {
                "success": False,
                "error_type": "InputValidationError",
                "error_message": validation_msg,
                "data": None
            }

        self.add_to_history("user", cleaned_input)

        try:
            # âœ… å…³é”®ä¿®å¤ï¼šè·å–ä¸Šä¸‹æ–‡å¹¶ä¼ å…¥
            context_history = self.get_conversation_context()

            # âœ… åªè°ƒç”¨ä¸€æ¬¡ï¼Œä¸”ä¼ å…¥ä¸Šä¸‹æ–‡
            response = self.agent.process_with_tools(
                prompt=cleaned_input,
                context_history=context_history  # ğŸ‘ˆ ä¼ å…¥ä¸Šä¸‹æ–‡ï¼
            )

            if response["success"]:
                parsed_data = response.get("parsed_data")
                if isinstance(parsed_data, dict):
                    assistant_reply = parsed_data.get("generated_copy") or parsed_data.get("final_answer") or str(parsed_data)
                elif isinstance(parsed_data, (int, float)):
                    assistant_reply = str(parsed_data)
                else:
                    assistant_reply = response.get("data", "")

                self.add_to_history("assistant", assistant_reply)
                return response
            else:
                error_msg = f"åŠ©æ‰‹æš‚æ—¶æ— æ³•å›åº”: {response['error_message']}"
                self.add_to_history("assistant", error_msg)
                return response

        except Exception as e:
            error_msg = f"å¯¹è¯å¤„ç†å‡ºé”™: {str(e)}"
            self.add_to_history("assistant", error_msg)
            logger.error(error_msg)
            return {
                "success": False,
                "error_type": "ConversationError",
                "error_message": error_msg,
                "data": None
            }


def interactive_chat():
    print("=== AI å¯¹è¯åŠ©æ‰‹ ===")
    print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºå¯¹è¯")
    print("è¾“å…¥ 'clear' æ¸…ç©ºå¯¹è¯å†å²")
    print("è¾“å…¥ 'history' æŸ¥çœ‹å¯¹è¯å†å²")
    print("-" * 30)

    agent = ConversationAgent()

    while True:
        try:
            user_input = input("\næ‚¨: ").strip()

            if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                print("å†è§ï¼")
                break
            elif user_input.lower() == 'clear':
                agent.clear_history()
                print("ğŸ¤– åŠ©æ‰‹: å¯¹è¯å†å²å·²æ¸…ç©º")
                continue
            elif user_input.lower() == 'history':
                history = agent.get_conversation_context()
                if history:
                    print("ğŸ¤– å¯¹è¯å†å²:")
                    for i, msg in enumerate(history, 1):
                        print(f"  {i}. [{msg['role']}] {msg['content']}")
                else:
                    print("ğŸ¤– åŠ©æ‰‹: å½“å‰æ²¡æœ‰å¯¹è¯å†å²")
                continue
            elif not user_input:
                print("ğŸ¤– åŠ©æ‰‹: è¯·è¾“å…¥æœ‰æ•ˆå†…å®¹")
                continue

            result = agent.chat(user_input)

            if result["success"]:
                response_data = result.get("parsed_data") or result.get("data")
                if isinstance(response_data, dict):
                    content = response_data.get("generated_copy") or response_data.get("final_answer") or str(response_data)
                else:
                    content = response_data
                print(f"ğŸ¤– åŠ©æ‰‹: {content}")
            else:
                print(f"ğŸ¤– åŠ©æ‰‹: {result['error_message']}")

        except KeyboardInterrupt:
            print("\n\nå¯¹è¯è¢«ä¸­æ–­ï¼Œå†è§ï¼")
            break
        except Exception as e:
            print(f"ğŸ¤– åŠ©æ‰‹: å‘ç”Ÿé”™è¯¯ - {str(e)}")


if __name__ == '__main__':
    interactive_chat()